# OSSBIG AI engineering team 2024

This is the central repository for the OSSBIG AI engineering team.

## General Informations

### Useful Links

- Benchmark Referenz: https://nicholas.carlini.com/writing/2024/my-benchmark-for-large-language-models.html
- Neue Ver√∂ffentlichung: https://opencodeinterpreter.github.io/#example
- GPT from Numpy: https://jaykmody.com/blog/gpt-from-scratch/

### Karpathy - Build GPT From Scratch

- Lets build the GPT Tokenizer: https://youtu.be/zduSFxRajkE?si=oiY3IYLJjNB3nR86
- The spelled-out intro to language modeling: building makemore: https://youtu.be/PaCmpygFfXo?si=Xo-7vP22l-I6l028
- Building makemore Part 2: MLP: https://youtu.be/TCH_1BHY58I?si=Ozu9nNz6EAiBMAFP
- Building makemore Part 3: Activations & Gradients, BatchNorm: https://youtu.be/P6sfmUTpUmc?si=qNfH2TI5QzDh4gVa
- Building makemore Part 4: Becoming a Backprop Ninja: https://youtu.be/q8SA3rM6ckI?si=_50lnWJpjG4iwknc

## OSSBIG

This are the links to the stuff that was generated for the OSSBIG.

### Workbooks and Repositories

- Modified IDEA Plugin (Branch KRM) to work with LLMs: https://github.com/mankra/llm-intellij
- CUDA acceleration in C: https://colab.research.google.com/drive/1N50mFGvlg0CFGDONdsS0ZQL2NyJEAMMt#scrollTo=HLdoj4cz-xal
- CUDA code repository (Branch CUDA): https://github.com/mankra/llama2.c

### Hugging Face OSSBIG Links

- endless-sky dataset for finetuning: https://huggingface.co/datasets/ossbig2024/endless-sky-master
- fltk dataset for finetuning: https://huggingface.co/datasets/ossbig2024/fltk-1.4.x
- List of all OSSBIG inference Endpoints: https://ui.endpoints.huggingface.co/ossbig2024/endpoints/dedicated

### Inference Endpoints

- starcoder (not modified): https://dg6m2lge10naythk.us-east-1.aws.endpoints.huggingface.cloud
- starcoder finetuned with fltk: https://wzggtcyqoo8yqru1.us-east-1.aws.endpoints.huggingface.cloud
- starcoder finetuned with endless-sky: https://qoge3l92yjotbvkl.us-east-1.aws.endpoints.huggingface.cloud
- starcoder base model: https://dq9aq8vpwch1ox86.us-east-1.aws.endpoints.huggingface.cloud
- code llamaa 7b: https://w31t8m73lcjkl8in.us-east-1.aws.endpoints.huggingface.cloud
- code llamaa 7b Instruct: https://aar1w1cxytqfah8l.us-east-1.aws.endpoints.huggingface.cloud

### Finetuning workbooks and repositories - not successfull

- Finetuning Code Repository (Data preperation, training): https://github.com/mankra/finetune
- Full finetuning workbook for endless-sky: https://colab.research.google.com/drive/1d99cUGdeHpu06pCMT-ioapw97EkR7ha1#scrollTo=zqtjrruXXKu9
- Full finetuning workbook for fltk: https://colab.research.google.com/drive/1u7PLPCE3bKHzhkSdxhcrFqko-k26pPfw#scrollTo=zqtjrruXXKu9
- PEFT finetuning workbook for endless-sky: https://colab.research.google.com/drive/18XqYBVkJv9lqwrnWuoI06ZUxQUuwiR1U#scrollTo=4AXJGt-ag4l5
- PEFT finetuning workbook for fltk: https://colab.research.google.com/drive/1dXruWXemEYI7srTbNAjEe_ESEvRFGBBT#scrollTo=v8MG0g-eEW9X
- Merge PEFT Layer with base model: https://colab.research.google.com/drive/1GWCLdRmZNXh6CbOMAwou4FRQCe19K-8x#scrollTo=dOIeFZfbiQmz
